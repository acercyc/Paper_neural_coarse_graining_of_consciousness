%%% Version 3.3 Generated 2018/01/26 %%%
%%% You will need to have the following packages installed: datetime, fmtcount, etoolbox, fcprefix, which are normally inlcuded in WinEdt. %%%
%%% In http://www.ctan.org/ you can find the packages and how to install them, if necessary. %%%
%%%  NB logo1.jpg is required in the path in order to correctly compile front page header %%%

\documentclass[utf8]{frontiersSCNS} 
% for Science, Engineering and Humanities and Social Sciences articles
%\documentclass[utf8]{frontiersHLTH} % for Health articles
%\documentclass[utf8]{frontiersFPHY} % for Physics and Applied Mathematics and Statistics articles
%\setcitestyle{square} % for Physics and Applied Mathematics and Statistics articles

% ============================================================================ %
%                                     Macro                                    %
% ============================================================================ %
\newcommand{\rewrite}[1]{\textcolor{ForestGreen}{\textit{"#1"}}}
\newcommand{\temp}[1]{\textcolor{Plum}{[[ #1 ]]\newline}}


% ============================================================================ %
%                                   Packages                                   %
% ============================================================================ %
\usepackage{url,hyperref,lineno,microtype,subcaption}

\usepackage[onehalfspacing]{setspace}

\usepackage{todonotes}

\usepackage{xcolor}

\usepackage[margin=2in]{geometry}


% ============================================================================ %


% ============================================================================ %
%                             Math request package                             %
% ============================================================================ %

% ============================================================================ %

\linenumbers


% Leave a blank line between paragraphs instead of using \\


\def\keyFont{\fontsize{8}{11}\helveticabold }
\def\firstAuthorLast{Sample {et~al.}} %use et al only if is more than 1 author
\def\Authors{Acer Y.C. Chang\,$^{1,*}$, Co-Author\,$^{2}$ and Ryota Kanai\,$^{1}$}
% Affiliations should be keyed to the author's name with superscript numbers and be listed as follows: Laboratory, Institute, Department, Organization, City, State abbreviation (USA, Canada, Australia), and Country (without detailed address information such as city zip codes or street names).
\def\Address{ARAYA, Inc., Tokyo, Japan}
% The Corresponding Author should be marked with an asterisk
% Provide the exact contact address (this time including street name and city zip code) and email of the corresponding author

\def\corrAuthor{Corresponding Author}

\def\corrEmail{acercyc@araya.org}



\begin{document}
\onecolumn
\firstpage{1}

\title[A neural coarse graining theory of consciousness]{A neural coarse graining theory of consciousness} 

\author[\firstAuthorLast ]{\Authors} %This field will be automatically populated
\address{} %This field will be automatically populated
\correspondance{} %This field will be automatically populated

\extraAuth{}% If there are more than 1 corresponding author, comment this line and uncomment the next one.
%\extraAuth{corresponding Author2 \\ Laboratory X2, Institute X2, Department X2, Organization X2, Street X2, City X2 , State XX2 (only USA, Canada and Australia), Zip Code2, X2 Country X2, email2@uni2.edu}
\maketitle


\begin{abstract}
Neural systems process information through different levels of organisation in a hierarchical manner. Information at lower levels is finer-grained and can be coarse-grained for higher level computation. However, one is aware of information processed only at specific levels.
Theorists have addressed this issue. For example, the intermediate level theory of consciousness suggests that the intermediate level seems to be privileged with respect to consciousness. It is true that we do not experience information processed by individual neurons which is always highly noisy. Besides, we have no conscious experience from interpersonal activities albeit massive interactions among individuals. Instead, neurophysiological evidence has been showing that conscious experience tends to covary with information encoded in coarse-grained neural states such as neural population codes. 
We argue that the neural states within the scope of the information closure determine the contents of consciousness and brain processes outside apart from the representations of that level  remain unconscious. This argument suggests a distinction between conscious and unconscious processing and provides a generic computational framework. Finally, using the deep learning network, we can measure information closure in deep hidden layers. Our preliminary results show that information closure representation emerged after learning. We further decoded the information from the representation and compared it with human conscious perception. 

\tiny
 \keyFont{ \section{Keywords:} theory of Consciousness, information closure, neural coarse-graining, level of analysis, keyword, keyword, keyword, keyword} %All article types: you may provide up to 8 keywords; at least 5 are mandatory.
\end{abstract}

% ============================================================================ %
%                                     Start                                    %
% ============================================================================ %

\section{Introduction}


\section{neural coarse-graining}
%TODO Single neurons are noisy 



%TODO Population coding
* \rewrite{Neural population code: the set of response features of a population of neurons that carry all information about the considered stimuli. These f
	
eatures consist of spatio-temporal sequences of action potentials distributed across neurons and/or time.}
	
		> The diverse response selectivity of sensory neurons
		> \rewrite{How a neural population represents information is partly determined by the diverse selectivity of individual neurons \cite{Shamir2014}}
	

		% ============================================================================ %
		% review ref
		% ============================================================================ %
		% \cite{Stanley2013}		
		% \cite{QuianQuiroga2009}
		
	
	%TODO sensory hierarchy
		* Sensors can only receive partial information
		* Through coarse-graining, higher level cortical areas can integrate those partial information to infer hidden causes. 





	\subsection{The advantage of NCG}
		\subsubsection{Resist to noise}
		\subsubsection{Operate on deterministic and abstract level}
		\subsubsection{Predictive power}
		\subsubsection{Reduce energy cost}	
	

\section{Non-trivial Information Closure}
	

	% ============================== what is closure ============================= %
	\rewrite{Our theoretical interest concerns the type of system that is a unity for and by itself and not only for an external observer distinguishing some entity from the rest of the world. This requires a system that can be described as a whole without reference to its environment. In systems theory, this property is usually referred to as closure.}\citep{BERTSCHINGER.2006}
	
	\rewrite{These concepts of closure play an important role in the architecture of systems theory, because they are used to
		1. define the system (in distinction to its environment) and to 
		2. explain the autonomy of the system.
	}

	\begin{quotation}
		Informational closure: The higher process is informationally closed, i.e., there is no information flow from the lower to the higher level. Knowledge of the microstate will not improve predictions of the macrostate \citep[p. 4]{PFANTE.2014}.
	\end{quotation}


	% ======================= trivial informational closure ====================== %
	\rewrite{A system that is independent from its environment trivially achieves informational closure.}
	\citep{BERTSCHINGER.2006}



	\subsection{Mathematical definition of information closure}
		\rewrite{The notion of informational closure refers to a situation where the information flow between the environment and the system tends to zero.
		}
		
		
		\cite{BERTSCHINGER.2006} suggests that information closure can be defined as the degree of information flow between environment and the system. 
		
		\begin{equation}
			\left.\begin{array} { r l } { J _ { n } ( E \rightarrow S ) } & { = M I ( S _ { n + 1} ; E _ { n } | S _ { n } ) } \\ { } & { = H ( S _ { n + 1} | S _ { n } ) - H ( S _ { n + 1} | S _ { n } ,E _ { n } ) } \\ { } & { = H ( E _ { n } | S _ { n } ) - H ( E _ { n } | S _ { n } ,S _ { n + 1} ) } \\ { } & { = H ( E _ { n } | S _ { n } ) - H ( E _ { n } | S _ { n } ,S _ { n + 1} ) } \end{array} \right.
		\end{equation}
	
	
	
		% =============================== Decompose IC =============================== %				
%		\begin{align}
%			M I ( S _ { n + 1} ; E _ { n } | S _ { n } ) = M I ( S _ { n + 1} ; E _ { n } ) - ( M I ( S _ { n + 1} ; S _ { n } ) - M I ( S _ { n + 1} ; S _ { n } | E _ { n } ) )
%		\end{align}
	
	
	\subsection{Non-trivial information closure}
	Information closure could be trivial. That is, when a system is fully independent from the environment, no information can flow into the system from the environment and also leak to the environment from the system. 
	
	Equa. xxxx shows the mathematical description of trivial information closure. When mutual information between the environment and system future state close to 0, and the system transition is independent from the environment, the system can reach informational closure. However, such systems do not have any functional meaning and evolutional advantages. \\
	Therefore, it's important to ensure the informational closure that the system reach is non-trivial.\\
	
	\temp{cite 2006 and nic's paper}
	To achieve non-trivial information closure, \\
	\citep{BERTSCHINGER.2006}\\
	\citep{guttenberg2016neural}
	
	
		% ============================================================================ %
		%                           I don't know what happen                           %
		% ============================================================================ %		
%		\begin{equation}	
%			\begin{align}
%				{ M I ( S _ { n + 1} ; E _ { n } ) } &= 0&\textmd{and}\\ 
%				M I ( S _ { n + 1} ; S _ { n } ) - M I ( S _ { n + 1} ; S _ { n } | E _ { n } ) &= 0
%			\end{align}
%		\end{equation}
		% ???????????????????????????????????????????????????????????????????????????? %
	
	
	\subsection{how to achieve information closure}
	\rewrite{This demonstrates that a system exhibiting certain internal regularities as measured by $A^* = MI(Sn+1; Sn)$ can achieve informational closure either by gaining information about the environment or by increased autonomy, i.e. by becoming unpredictable or uncontrollable from the
		(13) environment. Therefore, information about the environment, i.e. modeling, and autonomy can be considered as complementary strategies for achieving informational closure.}
	
	\subsection{information closure and Level Identification}	

	
	
\section{My claim of consciousness}
	* We claim that the coarse-grained state in the information closure determines contents of consciousness. 
	* It's important that not the neural states but the coarse-grained state determine contents of consciousness. 
	
	
	% ============================================================================ %
	%                         Information and system theory                        %
	%                                                                              %
	% ============================================================================ %
	\subsection{Information and system theory}
		\temp{Closure can define a system, consciousness is information}
		\temp{Could be linked to system theory, but may need help}
		
		\rewrite{This self-referential distinction from its environment therefore gives rise to the specific autonomy of such a system. Consequently, in systems theory, closure properties and autonomy are considered to be closely related concepts which are both at the heart of defining the system itself.
		}
	

\section{Biological Evidence of information closure in neural system}

	% Internal self-predictive mechanism	
	\cite{sederberg2018learning}


\section{Relation to empirical findings}
	\subsection{Explain normal and abnormal conscious/non-conscious experience}
	
%		Binocular rivalry
%		Hallucinations
%		subliminal perception
%		blindsight    
%		reflex is nonconscious
%		Procedure memory is state dependent
%		from conscious to unconscious processes
%		What happen to lesion
%		Sleep         

%		Perceptual overflow
%		Discrete vs continuous
%		Trace conditioning and delay conditioning
%		agnosia


%		Attention
%		Top-down attention

	\subsection{Deterministic vs probabilistic}
	\cite{dehaene2017consciousness}
	\cite{vul2008temporal, moreno2011bayesian, asplund2014attentional, vul2009attention}
	
\section{Comparison with other theories}
	\subsection{Intermediate Level Theory}
	\subsection{Global Workspace}
	

	\subsubsection{Ignition in GWT}
 	\temp{Explain ignite}
	
	
	\subsection{Sensorimotor contingency}
	\subsection{IIT}
	\subsection{Internal simulation and self-modeling}

\section{counterintuitive prediction}
	% To make a closure, we may discard some information! But what info?
	% Critical prediction that can test the the theory and IIT: CUT! Split brain

\section{Evolution of conscious mind}
	\cite{dennett2008kinds}

\section{Conclusion}
	NCC: To find NCC, it's not about where and when, it's about scale and level of discription


% ============================================================================ %
%                                      End                                     %
% ============================================================================ %

\section*{Funding}
Details of all funding sources should be provided, including grant numbers if applicable. Please ensure to add all necessary funding information, as after publication this is no longer possible.

\section*{Acknowledgements}
This is a short text to acknowledge the contributions of specific colleagues, institutions, or agencies that aided the efforts of the authors.

\section*{Supplemental Data}
 \href{http://home.frontiersin.org/about/author-guidelines#SupplementaryMaterial}{Supplementary Material} should be uploaded separately on submission, if there are Supplementary Figures, please include the caption in the same file as the figure. LaTeX Supplementary Material templates can be found in the Frontiers LaTeX folder.

\bibliographystyle{frontiersinSCNS_ENG_HUMS} % for Science, Engineering and Humanities and Social Sciences articles, for Humanities and Social Sciences articles please include page numbers in the in-text citations
%\bibliographystyle{frontiersinHLTH&FPHY} % for Health, Physics and Mathematics articles
\bibliography{ref}

%%% Make sure to upload the bib file along with the tex file and PDF
%%% Please see the test.bib file for some examples of references

\section*{Figure captions}

%%% Please be aware that for original research articles we only permit a combined number of 15 figures and tables, one figure with multiple subfigures will count as only one figure.
%%% Use this if adding the figures directly in the mansucript, if so, please remember to also upload the files when submitting your article
%%% There is no need for adding the file termination, as long as you indicate where the file is saved. In the examples below the files (logo1.eps and logos.eps) are in the Frontiers LaTeX folder
%%% If using *.tif files convert them to .jpg or .png
%%%  NB logo1.eps is required in the path in order to correctly compile front page header %%%

\begin{figure}[h!]
\begin{center}
\includegraphics[width=10cm]{logo1}% This is a *.eps file
\end{center}
\caption{ Enter the caption for your figure here.  Repeat as  necessary for each of your figures}\label{fig:1}
\end{figure}

\end{document}
